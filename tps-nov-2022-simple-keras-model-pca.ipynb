{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nfrom pathlib import Path\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMClassifier\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') \nimport random \nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n\n\nfrom sklearn.metrics import log_loss\n\npath = Path('/kaggle/input/tabular-playground-series-nov-2022/')\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-26T04:24:32.361664Z","iopub.execute_input":"2022-11-26T04:24:32.362325Z","iopub.status.idle":"2022-11-26T04:24:35.471998Z","shell.execute_reply.started":"2022-11-26T04:24:32.362241Z","shell.execute_reply":"2022-11-26T04:24:35.470801Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"submission = pd.read_csv(path / 'sample_submission.csv', index_col='id')\nlabels = pd.read_csv(path / 'train_labels.csv', index_col='id')\n\n# the ids of the submission rows (useful later)\nsub_ids = submission.index\n\n# the ids of the labeled rows (useful later)\ngt_ids = labels.index \n\n# list of files in the submission folder\nsubs = sorted(os.listdir(path / 'submission_files'))","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:24:35.477429Z","iopub.execute_input":"2022-11-26T04:24:35.478344Z","iopub.status.idle":"2022-11-26T04:24:35.733675Z","shell.execute_reply.started":"2022-11-26T04:24:35.478307Z","shell.execute_reply":"2022-11-26T04:24:35.732716Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Downloading all data to X_train dataframe**","metadata":{}},{"cell_type":"code","source":"s0 = pd.read_csv(path / 'submission_files' / subs[0], index_col='id')\n\nX_train = np.zeros((s0.shape[0], len(subs)))\nfor i, name in enumerate(subs):\n    sub = pd.read_csv(path / 'submission_files' / name, index_col='id')\n    X_train[:,i] = sub.pred.values\nX_train = pd.DataFrame(X_train, columns=subs)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:24:35.735138Z","iopub.execute_input":"2022-11-26T04:24:35.735690Z","iopub.status.idle":"2022-11-26T04:26:46.888891Z","shell.execute_reply.started":"2022-11-26T04:24:35.735639Z","shell.execute_reply":"2022-11-26T04:26:46.887947Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:26:46.893108Z","iopub.execute_input":"2022-11-26T04:26:46.894989Z","iopub.status.idle":"2022-11-26T04:26:46.927304Z","shell.execute_reply.started":"2022-11-26T04:26:46.894960Z","shell.execute_reply":"2022-11-26T04:26:46.926467Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   0.6222863195.csv  0.6223807245.csv  0.6225426578.csv  0.6247722291.csv  \\\n0          0.709336          0.799007          0.851891          0.537158   \n1          0.452988          0.364453          0.567582          0.354468   \n2          0.675462          0.842260          0.800013          0.525229   \n3          0.481046          0.577118          0.683032          0.541356   \n4          0.957339          0.910337          0.917322          0.874487   \n5          0.831414          0.598125          0.276116          0.525463   \n6          0.716171          0.424948          0.692054          0.328312   \n7          0.953687          0.934748          0.942298          0.858528   \n8          0.427233          0.372343          0.814237          0.555591   \n9          0.619906          0.719119          0.685702          0.640120   \n\n   0.6253455681.csv  0.6254850917.csv  0.6255093621.csv  0.6260141578.csv  \\\n0          0.623930          0.705970          0.503437          0.633185   \n1          0.513818          0.584119          0.454809          0.238501   \n2          0.692071          0.715418          0.651008          0.609124   \n3          0.630088          0.664514          0.413373          0.508210   \n4          0.787595          0.854273          0.843846          0.876749   \n5          0.734328          0.520369          0.081827          0.532379   \n6          0.622229          0.687056          0.502608          0.501735   \n7          0.794114          0.846232          0.841102          0.951427   \n8          0.533184          0.609211          0.552825          0.402674   \n9          0.659804          0.705191          0.497439          0.563905   \n\n   0.6263493693.csv  0.6272779211.csv  ...  0.7519100517.csv  \\\n0          0.641550          0.666604  ...          0.769207   \n1          0.472171          0.522314  ...          0.640052   \n2          0.691198          0.609994  ...          0.812841   \n3          0.526140          0.584565  ...          0.824703   \n4          0.821128          0.913054  ...          0.934803   \n5          0.821128          0.904294  ...          0.908995   \n6          0.611488          0.580623  ...          0.779942   \n7          0.775044          0.941849  ...          0.933843   \n8          0.509153          0.569622  ...          0.587888   \n9          0.543911          0.529731  ...          0.808328   \n\n   0.7519556278.csv  0.7520219713.csv  0.7521219579.csv  0.7522329272.csv  \\\n0          0.750250          0.663370          0.739333          0.822384   \n1          0.794052          0.721298          0.804369          0.620626   \n2          0.779859          0.865657          0.828493          0.763010   \n3          0.799698          0.800130          0.716604          0.603779   \n4          0.900150          0.960911          0.906037          0.961240   \n5          0.823174          0.912174          0.930805          0.571190   \n6          0.716931          0.689678          0.661001          0.856190   \n7          0.912999          0.930557          0.946958          0.985094   \n8          0.681688          0.661960          0.608619          0.667168   \n9          0.776024          0.778681          0.821828          0.814284   \n\n   0.7523602310.csv  0.7526089604.csv  0.7526999358.csv  0.7551167673.csv  \\\n0          0.749498          0.729800          0.867847          0.745888   \n1          0.733606          0.816942          0.814229          0.598331   \n2          0.802883          0.806891          0.896058          0.855776   \n3          0.708499          0.844837          0.853057          0.850657   \n4          0.935608          0.889757          0.978505          0.953681   \n5          0.926527          0.889757          0.939157          0.908295   \n6          0.709248          0.626589          0.575874          0.726107   \n7          0.970721          0.872210          0.971870          0.933964   \n8          0.617447          0.659957          0.808672          0.628330   \n9          0.808427          0.753920          0.816997          0.671402   \n\n   0.7575039918.csv  \n0             0.787  \n1             0.547  \n2             0.667  \n3             0.622  \n4             0.934  \n5             0.935  \n6             0.434  \n7             0.837  \n8             1.000  \n9             0.658  \n\n[10 rows x 5000 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.6222863195.csv</th>\n      <th>0.6223807245.csv</th>\n      <th>0.6225426578.csv</th>\n      <th>0.6247722291.csv</th>\n      <th>0.6253455681.csv</th>\n      <th>0.6254850917.csv</th>\n      <th>0.6255093621.csv</th>\n      <th>0.6260141578.csv</th>\n      <th>0.6263493693.csv</th>\n      <th>0.6272779211.csv</th>\n      <th>...</th>\n      <th>0.7519100517.csv</th>\n      <th>0.7519556278.csv</th>\n      <th>0.7520219713.csv</th>\n      <th>0.7521219579.csv</th>\n      <th>0.7522329272.csv</th>\n      <th>0.7523602310.csv</th>\n      <th>0.7526089604.csv</th>\n      <th>0.7526999358.csv</th>\n      <th>0.7551167673.csv</th>\n      <th>0.7575039918.csv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.709336</td>\n      <td>0.799007</td>\n      <td>0.851891</td>\n      <td>0.537158</td>\n      <td>0.623930</td>\n      <td>0.705970</td>\n      <td>0.503437</td>\n      <td>0.633185</td>\n      <td>0.641550</td>\n      <td>0.666604</td>\n      <td>...</td>\n      <td>0.769207</td>\n      <td>0.750250</td>\n      <td>0.663370</td>\n      <td>0.739333</td>\n      <td>0.822384</td>\n      <td>0.749498</td>\n      <td>0.729800</td>\n      <td>0.867847</td>\n      <td>0.745888</td>\n      <td>0.787</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.452988</td>\n      <td>0.364453</td>\n      <td>0.567582</td>\n      <td>0.354468</td>\n      <td>0.513818</td>\n      <td>0.584119</td>\n      <td>0.454809</td>\n      <td>0.238501</td>\n      <td>0.472171</td>\n      <td>0.522314</td>\n      <td>...</td>\n      <td>0.640052</td>\n      <td>0.794052</td>\n      <td>0.721298</td>\n      <td>0.804369</td>\n      <td>0.620626</td>\n      <td>0.733606</td>\n      <td>0.816942</td>\n      <td>0.814229</td>\n      <td>0.598331</td>\n      <td>0.547</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.675462</td>\n      <td>0.842260</td>\n      <td>0.800013</td>\n      <td>0.525229</td>\n      <td>0.692071</td>\n      <td>0.715418</td>\n      <td>0.651008</td>\n      <td>0.609124</td>\n      <td>0.691198</td>\n      <td>0.609994</td>\n      <td>...</td>\n      <td>0.812841</td>\n      <td>0.779859</td>\n      <td>0.865657</td>\n      <td>0.828493</td>\n      <td>0.763010</td>\n      <td>0.802883</td>\n      <td>0.806891</td>\n      <td>0.896058</td>\n      <td>0.855776</td>\n      <td>0.667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.481046</td>\n      <td>0.577118</td>\n      <td>0.683032</td>\n      <td>0.541356</td>\n      <td>0.630088</td>\n      <td>0.664514</td>\n      <td>0.413373</td>\n      <td>0.508210</td>\n      <td>0.526140</td>\n      <td>0.584565</td>\n      <td>...</td>\n      <td>0.824703</td>\n      <td>0.799698</td>\n      <td>0.800130</td>\n      <td>0.716604</td>\n      <td>0.603779</td>\n      <td>0.708499</td>\n      <td>0.844837</td>\n      <td>0.853057</td>\n      <td>0.850657</td>\n      <td>0.622</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.957339</td>\n      <td>0.910337</td>\n      <td>0.917322</td>\n      <td>0.874487</td>\n      <td>0.787595</td>\n      <td>0.854273</td>\n      <td>0.843846</td>\n      <td>0.876749</td>\n      <td>0.821128</td>\n      <td>0.913054</td>\n      <td>...</td>\n      <td>0.934803</td>\n      <td>0.900150</td>\n      <td>0.960911</td>\n      <td>0.906037</td>\n      <td>0.961240</td>\n      <td>0.935608</td>\n      <td>0.889757</td>\n      <td>0.978505</td>\n      <td>0.953681</td>\n      <td>0.934</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.831414</td>\n      <td>0.598125</td>\n      <td>0.276116</td>\n      <td>0.525463</td>\n      <td>0.734328</td>\n      <td>0.520369</td>\n      <td>0.081827</td>\n      <td>0.532379</td>\n      <td>0.821128</td>\n      <td>0.904294</td>\n      <td>...</td>\n      <td>0.908995</td>\n      <td>0.823174</td>\n      <td>0.912174</td>\n      <td>0.930805</td>\n      <td>0.571190</td>\n      <td>0.926527</td>\n      <td>0.889757</td>\n      <td>0.939157</td>\n      <td>0.908295</td>\n      <td>0.935</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.716171</td>\n      <td>0.424948</td>\n      <td>0.692054</td>\n      <td>0.328312</td>\n      <td>0.622229</td>\n      <td>0.687056</td>\n      <td>0.502608</td>\n      <td>0.501735</td>\n      <td>0.611488</td>\n      <td>0.580623</td>\n      <td>...</td>\n      <td>0.779942</td>\n      <td>0.716931</td>\n      <td>0.689678</td>\n      <td>0.661001</td>\n      <td>0.856190</td>\n      <td>0.709248</td>\n      <td>0.626589</td>\n      <td>0.575874</td>\n      <td>0.726107</td>\n      <td>0.434</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.953687</td>\n      <td>0.934748</td>\n      <td>0.942298</td>\n      <td>0.858528</td>\n      <td>0.794114</td>\n      <td>0.846232</td>\n      <td>0.841102</td>\n      <td>0.951427</td>\n      <td>0.775044</td>\n      <td>0.941849</td>\n      <td>...</td>\n      <td>0.933843</td>\n      <td>0.912999</td>\n      <td>0.930557</td>\n      <td>0.946958</td>\n      <td>0.985094</td>\n      <td>0.970721</td>\n      <td>0.872210</td>\n      <td>0.971870</td>\n      <td>0.933964</td>\n      <td>0.837</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.427233</td>\n      <td>0.372343</td>\n      <td>0.814237</td>\n      <td>0.555591</td>\n      <td>0.533184</td>\n      <td>0.609211</td>\n      <td>0.552825</td>\n      <td>0.402674</td>\n      <td>0.509153</td>\n      <td>0.569622</td>\n      <td>...</td>\n      <td>0.587888</td>\n      <td>0.681688</td>\n      <td>0.661960</td>\n      <td>0.608619</td>\n      <td>0.667168</td>\n      <td>0.617447</td>\n      <td>0.659957</td>\n      <td>0.808672</td>\n      <td>0.628330</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.619906</td>\n      <td>0.719119</td>\n      <td>0.685702</td>\n      <td>0.640120</td>\n      <td>0.659804</td>\n      <td>0.705191</td>\n      <td>0.497439</td>\n      <td>0.563905</td>\n      <td>0.543911</td>\n      <td>0.529731</td>\n      <td>...</td>\n      <td>0.808328</td>\n      <td>0.776024</td>\n      <td>0.778681</td>\n      <td>0.821828</td>\n      <td>0.814284</td>\n      <td>0.808427</td>\n      <td>0.753920</td>\n      <td>0.816997</td>\n      <td>0.671402</td>\n      <td>0.658</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 5000 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Dropping bad datasets**\nor clipping 'bad' values\nand dropping columns with inverted predictions","metadata":{}},{"cell_type":"code","source":"X_train = X_train.clip(0.0000001, 0.99999999)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:26:46.930238Z","iopub.execute_input":"2022-11-26T04:26:46.930502Z","iopub.status.idle":"2022-11-26T04:26:51.063442Z","shell.execute_reply.started":"2022-11-26T04:26:46.930477Z","shell.execute_reply":"2022-11-26T04:26:51.062483Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score\naucs = {}\nacc = {}\n\nfor column in X_train.columns:\n    aucs[column] = roc_auc_score(labels, X_train[:20000][column])\n    acc[column] = accuracy_score(labels, np.round(X_train[:20000][column]))\n    \nauc_df = pd.DataFrame.from_dict(aucs, orient='index').squeeze().rename('AUC')\nacc_df = pd.DataFrame.from_dict(acc, orient='index').squeeze().rename('ACC')\nprint('Models with flipped probabilites: ')\nprint(auc_df[auc_df.lt(0.5)]) \nprint(acc_df[acc_df.lt(0.5)]) ","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:26:51.065085Z","iopub.execute_input":"2022-11-26T04:26:51.065485Z","iopub.status.idle":"2022-11-26T04:27:40.678484Z","shell.execute_reply.started":"2022-11-26T04:26:51.065447Z","shell.execute_reply":"2022-11-26T04:27:40.677513Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Models with flipped probabilites: \n0.6932630537.csv    0.489735\n0.6952756302.csv    0.437338\n0.6962369747.csv    0.486196\n0.7069486042.csv    0.474238\n0.7168457192.csv    0.495189\n0.7215003044.csv    0.495341\n0.7366981883.csv    0.495000\n0.7450339370.csv    0.483432\nName: AUC, dtype: float64\n0.6885896550.csv    0.47435\n0.6952756302.csv    0.46235\n0.6962369747.csv    0.48970\n0.6982037018.csv    0.49355\n0.6999220673.csv    0.49205\n0.7069486042.csv    0.44600\n0.7168457192.csv    0.49510\n0.7215003044.csv    0.49995\n0.7246302099.csv    0.49465\n0.7366981883.csv    0.49815\n0.7395879372.csv    0.49085\n0.7450339370.csv    0.49960\nName: ACC, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"auc_df.plot.hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:40.679809Z","iopub.execute_input":"2022-11-26T04:27:40.680751Z","iopub.status.idle":"2022-11-26T04:27:41.083558Z","shell.execute_reply.started":"2022-11-26T04:27:40.680714Z","shell.execute_reply":"2022-11-26T04:27:41.082681Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:ylabel='Frequency'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"acc_df.plot.hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:41.085048Z","iopub.execute_input":"2022-11-26T04:27:41.085408Z","iopub.status.idle":"2022-11-26T04:27:41.444677Z","shell.execute_reply.started":"2022-11-26T04:27:41.085373Z","shell.execute_reply":"2022-11-26T04:27:41.443761Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:ylabel='Frequency'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"drop_cols1 = list(auc_df[auc_df.lt(0.5)].index)\ndrop_cols2 = list(acc_df[acc_df.lt(0.5)].index)\n\nfor item in drop_cols1:\n    if item in drop_cols2:\n        drop_cols2.remove(item)\n\n# for column in drop_cols:\n#     X_train[column] = 1 - X_train[column]\nX_train = X_train.drop(drop_cols1, axis=1)\nX_train = X_train.drop(drop_cols2, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:41.446020Z","iopub.execute_input":"2022-11-26T04:27:41.446477Z","iopub.status.idle":"2022-11-26T04:27:43.139344Z","shell.execute_reply.started":"2022-11-26T04:27:41.446441Z","shell.execute_reply":"2022-11-26T04:27:43.138378Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# X_train1 = X_train.copy()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:43.143487Z","iopub.execute_input":"2022-11-26T04:27:43.143799Z","iopub.status.idle":"2022-11-26T04:27:43.148109Z","shell.execute_reply.started":"2022-11-26T04:27:43.143773Z","shell.execute_reply":"2022-11-26T04:27:43.147055Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train_np = np.array(X_train)\nX_train = pd.DataFrame(X_train_np ** 0.9)\nX_train","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:43.149522Z","iopub.execute_input":"2022-11-26T04:27:43.150143Z","iopub.status.idle":"2022-11-26T04:27:48.396052Z","shell.execute_reply.started":"2022-11-26T04:27:43.150106Z","shell.execute_reply":"2022-11-26T04:27:48.394796Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"           0         1         2         3         4         5         6     \\\n0      0.734120  0.817138  0.865657  0.571600  0.654067  0.730984  0.539201   \n1      0.490318  0.403160  0.600656  0.393205  0.549197  0.616384  0.492092   \n2      0.702491  0.856844  0.818064  0.560162  0.718018  0.739782  0.679560   \n3      0.517569  0.609731  0.709573  0.575618  0.659874  0.692235  0.451552   \n4      0.961522  0.918929  0.925272  0.886294  0.806627  0.867835  0.858296   \n...         ...       ...       ...       ...       ...       ...       ...   \n39995  0.421098  0.327181  0.519748  0.319370  0.452388  0.500387  0.428870   \n39996  0.391238  0.338813  0.626544  0.384260  0.525226  0.541960  0.252278   \n39997  0.610145  0.700885  0.781540  0.519815  0.708856  0.691729  0.486276   \n39998  0.736929  0.810337  0.824577  0.827168  0.682519  0.694677  0.533304   \n39999  0.519668  0.570393  0.637638  0.488742  0.574518  0.610969  0.377261   \n\n           7         8         9     ...      4977      4978      4979  \\\n0      0.662792  0.670668  0.694194  ...  0.789658  0.772121  0.691163   \n1      0.275259  0.508967  0.557363  ...  0.669258  0.812576  0.745252   \n2      0.640081  0.717203  0.640904  ...  0.829860  0.799493  0.878236   \n3      0.543800  0.561037  0.616807  ...  0.840752  0.817774  0.818172   \n4      0.888357  0.837471  0.921397  ...  0.941127  0.909669  0.964750   \n...         ...       ...       ...  ...       ...       ...       ...   \n39995  0.265796  0.492746  0.362279  ...  0.595289  0.682702  0.645228   \n39996  0.329666  0.508316  0.354420  ...  0.616950  0.650530  0.665349   \n39997  0.571734  0.608193  0.638065  ...  0.762138  0.781615  0.794502   \n39998  0.954952  0.556082  0.579852  ...  0.723820  0.737695  0.806053   \n39999  0.696951  0.542237  0.412854  ...  0.669201  0.593621  0.592997   \n\n           4980      4981      4982      4983      4984      4985      4986  \n0      0.762002  0.838624  0.771425  0.753153  0.880235  0.768080  0.806078  \n1      0.822072  0.650949  0.756688  0.833628  0.831136  0.629865  0.581017  \n2      0.844228  0.783930  0.820705  0.824391  0.905946  0.869209  0.694566  \n3      0.740886  0.635024  0.733340  0.859203  0.866723  0.864528  0.652246  \n4      0.915022  0.965047  0.941856  0.900211  0.980634  0.958215  0.940399  \n...         ...       ...       ...       ...       ...       ...       ...  \n39995  0.637918  0.510778  0.611172  0.616787  0.576424  0.576288  0.303664  \n39996  0.617039  0.703944  0.647612  0.638319  0.610399  0.621899  0.748694  \n39997  0.833978  0.820379  0.832164  0.736838  0.877077  0.806058  0.604862  \n39998  0.797998  0.830369  0.800591  0.648834  0.794987  0.694007  0.670150  \n39999  0.569258  0.754027  0.572176  0.659030  0.736791  0.704357  0.607717  \n\n[40000 rows x 4987 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>4977</th>\n      <th>4978</th>\n      <th>4979</th>\n      <th>4980</th>\n      <th>4981</th>\n      <th>4982</th>\n      <th>4983</th>\n      <th>4984</th>\n      <th>4985</th>\n      <th>4986</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.734120</td>\n      <td>0.817138</td>\n      <td>0.865657</td>\n      <td>0.571600</td>\n      <td>0.654067</td>\n      <td>0.730984</td>\n      <td>0.539201</td>\n      <td>0.662792</td>\n      <td>0.670668</td>\n      <td>0.694194</td>\n      <td>...</td>\n      <td>0.789658</td>\n      <td>0.772121</td>\n      <td>0.691163</td>\n      <td>0.762002</td>\n      <td>0.838624</td>\n      <td>0.771425</td>\n      <td>0.753153</td>\n      <td>0.880235</td>\n      <td>0.768080</td>\n      <td>0.806078</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.490318</td>\n      <td>0.403160</td>\n      <td>0.600656</td>\n      <td>0.393205</td>\n      <td>0.549197</td>\n      <td>0.616384</td>\n      <td>0.492092</td>\n      <td>0.275259</td>\n      <td>0.508967</td>\n      <td>0.557363</td>\n      <td>...</td>\n      <td>0.669258</td>\n      <td>0.812576</td>\n      <td>0.745252</td>\n      <td>0.822072</td>\n      <td>0.650949</td>\n      <td>0.756688</td>\n      <td>0.833628</td>\n      <td>0.831136</td>\n      <td>0.629865</td>\n      <td>0.581017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.702491</td>\n      <td>0.856844</td>\n      <td>0.818064</td>\n      <td>0.560162</td>\n      <td>0.718018</td>\n      <td>0.739782</td>\n      <td>0.679560</td>\n      <td>0.640081</td>\n      <td>0.717203</td>\n      <td>0.640904</td>\n      <td>...</td>\n      <td>0.829860</td>\n      <td>0.799493</td>\n      <td>0.878236</td>\n      <td>0.844228</td>\n      <td>0.783930</td>\n      <td>0.820705</td>\n      <td>0.824391</td>\n      <td>0.905946</td>\n      <td>0.869209</td>\n      <td>0.694566</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.517569</td>\n      <td>0.609731</td>\n      <td>0.709573</td>\n      <td>0.575618</td>\n      <td>0.659874</td>\n      <td>0.692235</td>\n      <td>0.451552</td>\n      <td>0.543800</td>\n      <td>0.561037</td>\n      <td>0.616807</td>\n      <td>...</td>\n      <td>0.840752</td>\n      <td>0.817774</td>\n      <td>0.818172</td>\n      <td>0.740886</td>\n      <td>0.635024</td>\n      <td>0.733340</td>\n      <td>0.859203</td>\n      <td>0.866723</td>\n      <td>0.864528</td>\n      <td>0.652246</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.961522</td>\n      <td>0.918929</td>\n      <td>0.925272</td>\n      <td>0.886294</td>\n      <td>0.806627</td>\n      <td>0.867835</td>\n      <td>0.858296</td>\n      <td>0.888357</td>\n      <td>0.837471</td>\n      <td>0.921397</td>\n      <td>...</td>\n      <td>0.941127</td>\n      <td>0.909669</td>\n      <td>0.964750</td>\n      <td>0.915022</td>\n      <td>0.965047</td>\n      <td>0.941856</td>\n      <td>0.900211</td>\n      <td>0.980634</td>\n      <td>0.958215</td>\n      <td>0.940399</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>0.421098</td>\n      <td>0.327181</td>\n      <td>0.519748</td>\n      <td>0.319370</td>\n      <td>0.452388</td>\n      <td>0.500387</td>\n      <td>0.428870</td>\n      <td>0.265796</td>\n      <td>0.492746</td>\n      <td>0.362279</td>\n      <td>...</td>\n      <td>0.595289</td>\n      <td>0.682702</td>\n      <td>0.645228</td>\n      <td>0.637918</td>\n      <td>0.510778</td>\n      <td>0.611172</td>\n      <td>0.616787</td>\n      <td>0.576424</td>\n      <td>0.576288</td>\n      <td>0.303664</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>0.391238</td>\n      <td>0.338813</td>\n      <td>0.626544</td>\n      <td>0.384260</td>\n      <td>0.525226</td>\n      <td>0.541960</td>\n      <td>0.252278</td>\n      <td>0.329666</td>\n      <td>0.508316</td>\n      <td>0.354420</td>\n      <td>...</td>\n      <td>0.616950</td>\n      <td>0.650530</td>\n      <td>0.665349</td>\n      <td>0.617039</td>\n      <td>0.703944</td>\n      <td>0.647612</td>\n      <td>0.638319</td>\n      <td>0.610399</td>\n      <td>0.621899</td>\n      <td>0.748694</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>0.610145</td>\n      <td>0.700885</td>\n      <td>0.781540</td>\n      <td>0.519815</td>\n      <td>0.708856</td>\n      <td>0.691729</td>\n      <td>0.486276</td>\n      <td>0.571734</td>\n      <td>0.608193</td>\n      <td>0.638065</td>\n      <td>...</td>\n      <td>0.762138</td>\n      <td>0.781615</td>\n      <td>0.794502</td>\n      <td>0.833978</td>\n      <td>0.820379</td>\n      <td>0.832164</td>\n      <td>0.736838</td>\n      <td>0.877077</td>\n      <td>0.806058</td>\n      <td>0.604862</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>0.736929</td>\n      <td>0.810337</td>\n      <td>0.824577</td>\n      <td>0.827168</td>\n      <td>0.682519</td>\n      <td>0.694677</td>\n      <td>0.533304</td>\n      <td>0.954952</td>\n      <td>0.556082</td>\n      <td>0.579852</td>\n      <td>...</td>\n      <td>0.723820</td>\n      <td>0.737695</td>\n      <td>0.806053</td>\n      <td>0.797998</td>\n      <td>0.830369</td>\n      <td>0.800591</td>\n      <td>0.648834</td>\n      <td>0.794987</td>\n      <td>0.694007</td>\n      <td>0.670150</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>0.519668</td>\n      <td>0.570393</td>\n      <td>0.637638</td>\n      <td>0.488742</td>\n      <td>0.574518</td>\n      <td>0.610969</td>\n      <td>0.377261</td>\n      <td>0.696951</td>\n      <td>0.542237</td>\n      <td>0.412854</td>\n      <td>...</td>\n      <td>0.669201</td>\n      <td>0.593621</td>\n      <td>0.592997</td>\n      <td>0.569258</td>\n      <td>0.754027</td>\n      <td>0.572176</td>\n      <td>0.659030</td>\n      <td>0.736791</td>\n      <td>0.704357</td>\n      <td>0.607717</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 4987 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train['mean'] = X_train.mean(axis=1)\nX_train['std'] = X_train.std(axis=1)\n\n# X_train['min_pred'] = X_train1.min(axis = 1)\n# X_train['max_pred'] = X_train1.max(axis = 1)\n# X_train['median_pred'] = X_train1.median(axis = 1)\n# X_train['var_pred'] = X_train1.var(axis = 1)\n# X_train['q1_pred'] = X_train1.quantile(q=0.25, axis = 1)\n# X_train['q3_pred'] = X_train1.quantile(q=0.75, axis = 1)\n# X_train['skew_pred'] = X_train1.skew(axis = 1)\n# X_train['kurtosis_pred'] = X_train1.kurtosis(axis = 1)\n\n# X_train['var_pred'] = X_train['var_pred'] / X_train['var_pred'].max()\n# X_train['skew_pred'] = X_train['skew_pred'] / X_train['skew_pred'].max()\n# X_train['kurtosis_pred'] = X_train['kurtosis_pred'] / X_train['kurtosis_pred'].max()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:48.397914Z","iopub.execute_input":"2022-11-26T04:27:48.398346Z","iopub.status.idle":"2022-11-26T04:27:57.181472Z","shell.execute_reply.started":"2022-11-26T04:27:48.398298Z","shell.execute_reply":"2022-11-26T04:27:57.180390Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# X_train = X_train.loc[:, X_train.max()<=1]\n# X_train = X_train.loc[:, X_train.min()>=0]","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:57.182893Z","iopub.execute_input":"2022-11-26T04:27:57.183238Z","iopub.status.idle":"2022-11-26T04:27:57.189698Z","shell.execute_reply.started":"2022-11-26T04:27:57.183203Z","shell.execute_reply":"2022-11-26T04:27:57.188546Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:57.191424Z","iopub.execute_input":"2022-11-26T04:27:57.192496Z","iopub.status.idle":"2022-11-26T04:27:57.201436Z","shell.execute_reply.started":"2022-11-26T04:27:57.192461Z","shell.execute_reply":"2022-11-26T04:27:57.200354Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(40000, 4989)"},"metadata":{}}]},{"cell_type":"markdown","source":"**PCA**","metadata":{}},{"cell_type":"markdown","source":"Thanks to @infrarosso for PCA! Please, upvote his notebook!\nhttps://www.kaggle.com/code/infrarosso/tps-nov-2022-eda-lgbm-stacking\n(link for upvoting)","metadata":{}},{"cell_type":"code","source":"VARIANCE_TH = 0.98\n\npca = PCA()\npca_samples = pca.fit_transform(X_train)\ntotal = sum(pca.explained_variance_)\nk = 0\ncurrent_variance = 0\nwhile current_variance/total <= VARIANCE_TH:\n    current_variance += pca.explained_variance_[k]\n    k = k + 1\nprint(F\"{VARIANCE_TH*100:.0f}% explained variance with {k}/{len(X_train.columns)} features\")","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:27:57.203015Z","iopub.execute_input":"2022-11-26T04:27:57.203404Z","iopub.status.idle":"2022-11-26T04:32:40.201489Z","shell.execute_reply.started":"2022-11-26T04:27:57.203349Z","shell.execute_reply":"2022-11-26T04:32:40.199533Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"98% explained variance with 152/4989 features\n","output_type":"stream"}]},{"cell_type":"code","source":"pca=PCA(n_components=k)\nX_train_reduced = pd.DataFrame(pca.fit_transform(X_train))\nX_train_reduced.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:32:40.203268Z","iopub.execute_input":"2022-11-26T04:32:40.203666Z","iopub.status.idle":"2022-11-26T04:33:10.866624Z","shell.execute_reply.started":"2022-11-26T04:32:40.203611Z","shell.execute_reply":"2022-11-26T04:33:10.865436Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(40000, 152)"},"metadata":{}}]},{"cell_type":"code","source":"# X_train_reduced = X_train","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:10.868360Z","iopub.execute_input":"2022-11-26T04:33:10.868746Z","iopub.status.idle":"2022-11-26T04:33:10.874242Z","shell.execute_reply.started":"2022-11-26T04:33:10.868711Z","shell.execute_reply":"2022-11-26T04:33:10.873316Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X = X_train_reduced[0:20000]\nX_test = X_train_reduced[20000:]\ny = labels","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:10.875584Z","iopub.execute_input":"2022-11-26T04:33:10.876148Z","iopub.status.idle":"2022-11-26T04:33:10.885054Z","shell.execute_reply.started":"2022-11-26T04:33:10.876111Z","shell.execute_reply":"2022-11-26T04:33:10.883987Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:10.888239Z","iopub.execute_input":"2022-11-26T04:33:10.888498Z","iopub.status.idle":"2022-11-26T04:33:10.896094Z","shell.execute_reply.started":"2022-11-26T04:33:10.888475Z","shell.execute_reply":"2022-11-26T04:33:10.895124Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Simple Keras model**\nwith \n- Batchnormalization \n- Dropout\n- EarlyStopping\n- Learning rate exponential decay","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Lambda, Concatenate, Add, BatchNormalization, LeakyReLU\n\n# model = keras.Sequential([\n# #     layers.Dense(1024), \n# #     layers.LeakyReLU(alpha=0.3),\n# # #     layers.BatchNormalization(),\n# #     layers.Dropout(rate=0.3),\n# #     layers.Dense(512), \n# #     layers.LeakyReLU(alpha=0.3),\n# # #     layers.BatchNormalization(),\n# #     layers.Dropout(rate=0.3),\n#     layers.Dense(256), \n#     layers.LeakyReLU(alpha=0.3),\n# #     layers.BatchNormalization(),\n#     layers.Dropout(rate=0.1),\n#     layers.Dense(128),\n#     layers.LeakyReLU(alpha=0.3),\n# #     layers.BatchNormalization(),\n#     layers.Dropout(rate=0.1),\n#     layers.Dense(64),\n#     layers.LeakyReLU(alpha=0.3),\n# #     layers.BatchNormalization(),\n#     layers.Dropout(rate=0.1),\n#     layers.Dense(32),\n#     layers.LeakyReLU(alpha=0.3),\n# #     layers.BatchNormalization(),\n#     layers.Dropout(rate=0.1),\n#     layers.Dense(16),\n#     layers.LeakyReLU(alpha=0.3),\n# #     layers.BatchNormalization(),\n#     layers.Dropout(rate=0.1),\n#     layers.Dense(8),\n#     layers.LeakyReLU(alpha=0.3),\n# #     layers.BatchNormalization(),\n#     layers.Dropout(rate=0.1),\n#     layers.Dense(4),\n#     layers.LeakyReLU(alpha=0.3),\n#     layers.Dropout(rate=0.1),\n#     layers.Dense(2),\n#     layers.LeakyReLU(alpha=0.3),\n#     layers.Dense(1, activation='sigmoid'),\n# ])\n\n\n# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n#                     initial_learning_rate=0.0001,\n#                     decay_steps=1000,\n#                     decay_rate=0.9)\n# opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n# model.compile(\n#     optimizer=opt,\n#     loss='binary_crossentropy',\n#     metrics=['binary_accuracy'],\n# )\n# early_stopping = keras.callbacks.EarlyStopping(\n#     patience=30,\n#     min_delta=0.001,\n#     restore_best_weights=True,\n# )","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:10.897576Z","iopub.execute_input":"2022-11-26T04:33:10.898120Z","iopub.status.idle":"2022-11-26T04:33:16.002331Z","shell.execute_reply.started":"2022-11-26T04:33:10.898081Z","shell.execute_reply":"2022-11-26T04:33:16.001299Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42)\n\ndef test_nn(lr, sc=2, dec_r=0.65, bs=128, dr=0.2):\n    \n    input_ = Input(shape = X_train.shape[1])\n    d0 = Dense(1024 * sc // 5 + 1)(input_)\n    a0 = LeakyReLU()(d0)\n    dr0 = Dropout(rate=dr)(a0)\n    d01 = Dense(512 * sc // 5 + 1)(dr0)\n    a01 = LeakyReLU()(d01)\n    dr01 = Dropout(rate=dr)(a01)\n    d1 = Dense(256 * sc // 5 + 1)(dr01)\n    a1 = LeakyReLU()(d1)\n    dr1 = Dropout(rate=dr)(a1)\n    d2 = Dense(128 * sc // 5 + 1)(dr1)\n    a2 = LeakyReLU()(d2)\n    dr2 = Dropout(rate=dr)(a2)\n    d3 = Dense(64 * sc // 5 + 1)(dr2)\n    a3 = LeakyReLU()(d3)\n    dr3 = Dropout(rate=dr)(a3)\n    d4 = Dense(32 * sc // 5 + 1)(dr3)\n    a4 = LeakyReLU()(d4)\n    dr4 = Dropout(rate=dr)(a4)\n    d5 = Dense(16 * sc // 5 + 1)(dr4)\n    a5 = LeakyReLU()(d5)\n    dr5 = Dropout(rate=dr)(a5)\n#     concat1 = Concatenate()([dr5, input_])\n    d6 = Dense(8 * sc // 5 + 1)(dr5)\n    a6 = LeakyReLU()(d6)\n    dr6 = Dropout(rate=dr)(a6)\n#     concat2 = Concatenate()([dr6, input_])\n    d7 = Dense(4)(dr6)\n    a7 = LeakyReLU()(d7)\n    dr7 = Dropout(rate=dr)(a7)\n    concat3 = Concatenate()([dr7, input_])\n    d8 = Dense(2)(concat3)\n    a8 = LeakyReLU()(d8)\n    dr8 = Dropout(rate=dr)(a8)\n    out = Dense(1, activation='sigmoid')(dr8)\n    \n    model1 = Model(inputs=input_, outputs=out)\n    \n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n                    initial_learning_rate=lr,\n                    decay_steps=1000,\n                    decay_rate=dec_r)\n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     opt = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n    opt = keras.optimizers.Ftrl(learning_rate=lr_schedule)\n\n    model1.compile(\n    optimizer=opt,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n    )\n    early_stopping = keras.callbacks.EarlyStopping(\n    patience=30,\n    min_delta=0.001,\n    restore_best_weights=True,\n    )\n    \n    history = model1.fit(\n          X_train, y_train,\n          validation_data=(X_valid, y_valid),\n          batch_size=bs,\n          epochs=300,\n          callbacks=[early_stopping],\n          verbose=0,\n         )\n    \n    \n    return log_loss(labels, model1.predict(X))","metadata":{"execution":{"iopub.status.busy":"2022-11-26T05:17:05.398077Z","iopub.execute_input":"2022-11-26T05:17:05.398442Z","iopub.status.idle":"2022-11-26T05:17:05.440593Z","shell.execute_reply.started":"2022-11-26T05:17:05.398412Z","shell.execute_reply":"2022-11-26T05:17:05.439492Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# sc_val = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n# dr_val = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n# lr_val = [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01]\n# dec_r_val = [1, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6]\n# bs_val = [32, 64, 128, 256, 512, 1024, 2048]\n# res_test = []\n\n# for val in lr_val:\n#     res_test.append(test_nn(val))\n#     print('scale = ',  val, ',  result = ', res_test[-1])","metadata":{"execution":{"iopub.status.busy":"2022-11-26T05:17:14.770839Z","iopub.execute_input":"2022-11-26T05:17:14.771774Z","iopub.status.idle":"2022-11-26T05:20:10.724785Z","shell.execute_reply.started":"2022-11-26T05:17:14.771727Z","shell.execute_reply":"2022-11-26T05:20:10.723718Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"scale =  1e-05 ,  result =  0.6932766159117222\nscale =  5e-05 ,  result =  0.6940796726524829\nscale =  0.0001 ,  result =  0.6933589877188205\nscale =  0.0005 ,  result =  0.6932530830830336\nscale =  0.001 ,  result =  0.6915326069712638\nscale =  0.005 ,  result =  0.606089263746515\nscale =  0.01 ,  result =  0.5675499840654433\n","output_type":"stream"}]},{"cell_type":"code","source":"# test_nn(0.5)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T05:21:05.626716Z","iopub.execute_input":"2022-11-26T05:21:05.627076Z","iopub.status.idle":"2022-11-26T05:21:48.346598Z","shell.execute_reply.started":"2022-11-26T05:21:05.627047Z","shell.execute_reply":"2022-11-26T05:21:48.345567Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0.5233613361767144"},"metadata":{}}]},{"cell_type":"code","source":"# res_test","metadata":{"execution":{"iopub.status.busy":"2022-11-26T05:08:25.315808Z","iopub.execute_input":"2022-11-26T05:08:25.316544Z","iopub.status.idle":"2022-11-26T05:08:25.323260Z","shell.execute_reply.started":"2022-11-26T05:08:25.316508Z","shell.execute_reply":"2022-11-26T05:08:25.322249Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"[0.5343180115364657,\n 0.5245505342843942,\n 0.5254674781319977,\n 0.5272080251278821,\n 0.534142530922393,\n 0.5361577436995169,\n 0.5241544840319547,\n 0.5241106417487142,\n 0.5394537482756209]"},"metadata":{}}]},{"cell_type":"code","source":"# stop","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.516297Z","iopub.status.idle":"2022-11-26T04:33:19.516792Z","shell.execute_reply.started":"2022-11-26T04:33:19.516529Z","shell.execute_reply":"2022-11-26T04:33:19.516552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 30\n\nk_fold = StratifiedKFold(n_splits=n_folds, random_state=43, shuffle=True)\n\npreds = []\n\n# best_res = 1\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    lr=0.5\n    sc=2\n    dec_r=0.65\n    bs=128\n    dr=0.2\n\n    input_ = Input(shape = X_train.shape[1])\n    d0 = Dense(1024 * sc // 5 + 1)(input_)\n    a0 = LeakyReLU()(d0)\n    dr0 = Dropout(rate=dr)(a0)\n    d01 = Dense(512 * sc // 5 + 1)(dr0)\n    a01 = LeakyReLU()(d01)\n    dr01 = Dropout(rate=dr)(a01)\n    d1 = Dense(256 * sc // 5 + 1)(dr01)\n    a1 = LeakyReLU()(d1)\n    dr1 = Dropout(rate=dr)(a1)\n    d2 = Dense(128 * sc // 5 + 1)(dr1)\n    a2 = LeakyReLU()(d2)\n    dr2 = Dropout(rate=dr)(a2)\n    d3 = Dense(64 * sc // 5 + 1)(dr2)\n    a3 = LeakyReLU()(d3)\n    dr3 = Dropout(rate=dr)(a3)\n    d4 = Dense(32 * sc // 5 + 1)(dr3)\n    a4 = LeakyReLU()(d4)\n    dr4 = Dropout(rate=dr)(a4)\n    d5 = Dense(16 * sc // 5 + 1)(dr4)\n    a5 = LeakyReLU()(d5)\n    dr5 = Dropout(rate=dr)(a5)\n#     concat1 = Concatenate()([dr5, input_])\n    d6 = Dense(8 * sc // 5 + 1)(dr5)\n    a6 = LeakyReLU()(d6)\n    dr6 = Dropout(rate=dr)(a6)\n#     concat2 = Concatenate()([dr6, input_])\n    d7 = Dense(4)(dr6)\n    a7 = LeakyReLU()(d7)\n    dr7 = Dropout(rate=dr)(a7)\n    concat3 = Concatenate()([dr7, input_])\n    d8 = Dense(2)(concat3)\n    a8 = LeakyReLU()(d8)\n    dr8 = Dropout(rate=dr)(a8)\n    out = Dense(1, activation='sigmoid')(dr8)\n    \n    model1 = Model(inputs=input_, outputs=out)\n    \n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n                    initial_learning_rate=lr,\n                    decay_steps=1000,\n                    decay_rate=dec_r)\n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     opt = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n    opt = keras.optimizers.Ftrl(learning_rate=lr_schedule)\n\n    model1.compile(\n    optimizer=opt,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n    )\n    early_stopping = keras.callbacks.EarlyStopping(\n    patience=30,\n    min_delta=0.001,\n    restore_best_weights=True,\n    )\n    \n    history = model1.fit(\n          X_train, y_train,\n          validation_data=(X_valid, y_valid),\n          batch_size=2048,\n          epochs=300,\n          callbacks=[early_stopping],\n          verbose=1,\n         )\n    preds.append(model1.predict(X_test))\n    print('--------------------------------------------------------')\n    history_df = pd.DataFrame(history.history)\n    history_df.loc[1:, ['loss', 'val_loss']].plot()\n    history_df.loc[1:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n    print('--------------------------------------------------------')\n    print(\"Logloss valid = {}\".format(log_loss(y_valid, model1.predict(X_valid))))\n    res = log_loss(labels, model1.predict(X))\n    print(\"Logloss full = {}\".format(res))\n    \n#     if res < best_res:\n#         best_res = res\n#         model = model1\n\n# history = model.fit(\n#     X_train, y_train,\n#     validation_data=(X_valid, y_valid),\n#     batch_size=256,\n#     epochs=100,\n#     callbacks=[early_stopping],\n#     verbose=1,\n# )","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.520263Z","iopub.status.idle":"2022-11-26T04:33:19.520851Z","shell.execute_reply.started":"2022-11-26T04:33:19.520544Z","shell.execute_reply":"2022-11-26T04:33:19.520571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_df = pd.DataFrame(history.history)\n\n# history_df.loc[1:, ['loss', 'val_loss']].plot()\n# history_df.loc[1:, ['binary_accuracy', 'val_binary_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.522594Z","iopub.status.idle":"2022-11-26T04:33:19.523081Z","shell.execute_reply.started":"2022-11-26T04:33:19.522839Z","shell.execute_reply":"2022-11-26T04:33:19.522861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, random_state=43)\n\n# history = model.fit(\n#     X_train, y_train,\n#     validation_data=(X_valid, y_valid),\n#     batch_size=256,\n#     epochs=100,\n#     callbacks=[early_stopping],\n#     verbose=1,\n# )","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.525072Z","iopub.status.idle":"2022-11-26T04:33:19.525617Z","shell.execute_reply.started":"2022-11-26T04:33:19.525330Z","shell.execute_reply":"2022-11-26T04:33:19.525355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_df = pd.DataFrame(history.history)\n\n# history_df.loc[1:, ['loss', 'val_loss']].plot()\n# history_df.loc[1:, ['binary_accuracy', 'val_binary_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.526947Z","iopub.status.idle":"2022-11-26T04:33:19.527785Z","shell.execute_reply.started":"2022-11-26T04:33:19.527490Z","shell.execute_reply":"2022-11-26T04:33:19.527537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = log_loss(labels, model1.predict(X))\nscore","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.529667Z","iopub.status.idle":"2022-11-26T04:33:19.530154Z","shell.execute_reply.started":"2022-11-26T04:33:19.529897Z","shell.execute_reply":"2022-11-26T04:33:19.529920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Making prediction**","metadata":{}},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.531805Z","iopub.status.idle":"2022-11-26T04:33:19.532281Z","shell.execute_reply.started":"2022-11-26T04:33:19.532027Z","shell.execute_reply":"2022-11-26T04:33:19.532050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.average(np.array(preds),axis=0)\n# pred = model.predict(X_test)\npred","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.533936Z","iopub.status.idle":"2022-11-26T04:33:19.534433Z","shell.execute_reply.started":"2022-11-26T04:33:19.534182Z","shell.execute_reply":"2022-11-26T04:33:19.534205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = pd.DataFrame(pred)\npr.plot.hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.535756Z","iopub.status.idle":"2022-11-26T04:33:19.536553Z","shell.execute_reply.started":"2022-11-26T04:33:19.536300Z","shell.execute_reply":"2022-11-26T04:33:19.536329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.538387Z","iopub.status.idle":"2022-11-26T04:33:19.538872Z","shell.execute_reply.started":"2022-11-26T04:33:19.538614Z","shell.execute_reply":"2022-11-26T04:33:19.538636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.540519Z","iopub.status.idle":"2022-11-26T04:33:19.541706Z","shell.execute_reply.started":"2022-11-26T04:33:19.541431Z","shell.execute_reply":"2022-11-26T04:33:19.541462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['pred'] = pred\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.543761Z","iopub.status.idle":"2022-11-26T04:33:19.544239Z","shell.execute_reply.started":"2022-11-26T04:33:19.543985Z","shell.execute_reply":"2022-11-26T04:33:19.544007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-26T04:33:19.545979Z","iopub.status.idle":"2022-11-26T04:33:19.546455Z","shell.execute_reply.started":"2022-11-26T04:33:19.546215Z","shell.execute_reply":"2022-11-26T04:33:19.546236Z"},"trusted":true},"execution_count":null,"outputs":[]}]}